





# 语义分割综述（切记不要细说！）

## 1.初识语义分割

### 1.1.计算机视觉

​		目前，计算机视觉是深度学习领域最热门的研究领域之一。计算机视觉实际上是一个跨领域的**交叉学科**，包括计算机科学（图形、算法、理论、系统、体系结构），数学（信息检索、机器学习），工程学（机器人、语音、自然语言处理、图像处理），物理学（光学 ），生物学（神经科学）和心理学（认知科学）等等。许多科学家认为，计算机视觉为人工智能的发展开拓了道路。对于计算机视觉较严谨的定义有一下几种：

- “对图像中的客观对象构建明确而有意义的描述”（Ballard＆Brown，1982）
- “从一个或多个数字图像中计算三维世界的特性”（Trucco＆Verri，1998）
- “基于感知图像做出对客观对象和场景有用的决策”（Sockman＆Shapiro，2001）

## 1.2.语义分割

众所周知，计算机视觉有三大核心任务——分类、检测、分割，三者号称是深度学习炼丹师的“三大浪漫”。作为计算机视觉基础任务之一，语义分割历史悠久。分类针对整张图片，检测针对图片的局部，语义分割则如**图1**所示，旨在给输入图片上的每个像素赋予一个正确的语义标签。

![image-20210930155834395](../../../../images/computer_vision/semantic_segmentation/Overview/image-20210930155834395.png)

​		![image-20210930155846918](../../../../images/computer_vision/semantic_segmentation/Overview/image-20210930155846918.png)

<center>图1 语义分割示例</center><br></br>

### 1.3.语义分割与实例分割的区别

​		首先说说他们的共性，语义分割和实例分割都是从图像中分割出目标有效区域，即预测每个像素点所属的类别。不同的是语义分割不区分同类目标，而实例分割则需要区分同类目标的不同个体。如**图2**所示，两种分割方式均可以分割出各个目标的有效区域，不同的是示例分割可以区分不同的目标个体，如cube。

![image-20210930163709517](../../../../images/computer_vision/semantic_segmentation/Overview/image-20210930163709517.png)

<center>图2 语义分割和实例分割区别示例</center><br></br>

## 2.语义分割的发展

​			传统的分割算法已经推出了历史舞台，目前工业界常用的分割算法都是使用大数据驱动的深度学习模型。我们从深度学习的角度出发，细数一下基于深度学习的分割模型发展历程，如**表1**所示。另外，根据模型的创新方向不同，**图3**形象化的展示了表1所提及的方法的分类。

![Semantic_all](../../../../images/computer_vision/semantic_segmentation/Overview/Semantic_all.png)

<center>表1 语义分割方法总览</center><br></br>

![Sematic_divide](../../../../images/computer_vision/semantic_segmentation/Overview/Sematic_divide.png)

<center>图3 所提及方法的形象化展示</center><br></br>

​		我们将按照分割方法的发展路线，选取一些经典的方法对其进行介绍。感兴趣的朋友可以按照分类学习对应改进方向的方法。

​		2.1.1. FCN

​		2.1.2. U-net

​		2.1.3. SegNet

​		2.1.4. Deeplab V1

​		2.1.5. PSPnet

​		2.1.6. Deeplab V2

​		2.1.7. Deeplab V3

​		2.1.8. Deeplab V3+

​		2.1.9. 总结



## 3.常用数据集

​		关于分割的开源/闭源数据集数量众多，并且基于很多重大数据集举办了很多竞赛。为了综述的完整性考虑，对现有的经典数据集进行总结。值得争辩的是，对于机器学习来说数据是最重要的或者最重要的之一。当处理深度网络时，这种重要性更加明显。因此，收集正确的数据放入数据集对于任何基于深度学习的分割系统来说都是极为重要的。收集与创建一个足够大而且能够正确代表系统应用场景的数据集，需要大量的时间，需要领域专门知识来挑选相关信息，也需要相关的基础设施使得系统可以正确的理解与学习（捕捉到的数据）。这个任务的公式化过程虽然相比复杂的神经网络结构的定义要简单，但是其解决过程却是相关工作中最难的之一。因此，最明智的做法通常是使用一个现存的足够可以代表该问题应用场景的标准数据集。使用标准数据集还有一个好处就是可以使系统间的对比更加公平，实际上，许多数据集是为了与其他方法进行对比而不是给研究者测试其算法的，在对比过程中，会根据方法的实际表现得到一个公平的排序，其中不涉及任何数据随机选取的过程。

​		接下来我们将介绍语义分割领域最近最受欢迎的大规模数据集。所有列出的数据集均包含像素级别或点级别的标签。这个列表将根据数据内在属性分为3个部分：2维的或平面的RGB数据集，2.5维或带有深度信息的RGB（RGB-D）数据集，以及纯体数据或3维数据集。**表2**给出了这些数据集的概览，收录了所有本文涉及的数据集并提供了一些有用信息如他们的被构建的目的、类数、数据格式以及训练集、验证集、测试集划分情况。

![datasets_all](../../../../images/computer_vision/semantic_segmentation/Overview/datasets_all.png)

<center>表2 常用大规模数据集总览</center><br></br>

### 5.1.  2维数据集

​		自始至终，语义分割问题最关注的是二维图像。因此，二维数据集在所有类型中是最丰富的。本章我们讨论语义分割领域最流行的二维大规模数据集，这考虑到所有的包含二维表示如灰度或RGB图像的数据集。

#### 5.1.1.**[PASCAL视觉物体分类数据集（PASCAL-VOC）](http://host.robots.ox.ac.uk/pascal/VOC/voc2012/)**

​		包括一个标注了的图像数据集和五个不同的竞赛：分类、检测、分割、动作分类、人物布局。分割的竞赛很有趣：他的目标是为测试集里的每幅图像的每个像素预测其所属的物体类别。有21个类，包括轮子、房子、动物以及其他的：飞机、自行车、船、公共汽车、轿车、摩托车、火车、瓶子、椅子、餐桌、盆栽、沙发、显示器（或电视）、鸟、猫、狗、马、绵羊、人。如果某像素不属于任何类，那么背景也会考虑作为其标签。该数据集被分为两个子集：训练集1464张图像以及验证集1449张图像。测试集在竞赛中是私密的。争议的说，这个数据集是目前最受欢迎的语义分割数据集，因此很多相关领域卓越的工作将其方法提交到该数据集的评估服务器上，在其测试集上测试其方法的性能。方法可以只用该数据集训练，也可以借助其他的信息。另外，其方法排行榜是公开的而且可以在线查询。

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE1LmNuYmxvZ3MuY29tL2Jsb2cvMTEzMDA4My8yMDE3MDUvMTEzMDA4My0yMDE3MDUyNjIxMjg1OTQzNS02MTE3ODc1ODAucG5n?x-oss-process=image/format,png)

<center>图3 PASCAL-VOC数据集示例</center><br></br>

#### 5.1.2. **[PASCAL上下文数据集（PASCAL Context）](http://www.cs.stanford.edu/∼roozbeh/pascal-context/)**

​		对于PASCAL-VOC 2010识别竞赛的扩展，包含了对所有训练图像的像素级别的标注。共有540个类，包括原有的20个类及由PASCAL VOC分割数据集得来的图片背景，分为三大类，分别是物体、材料以及混合物。虽然种类繁多，但是只有59个常见类是较有意义的。由于其类别服从一个幂律分布，其中有很多类对于整个数据集来说是非常稀疏的。就这点而言，包含这59类的子集常被选作真实类别来对该数据集进行研究，其他类别一律重标为背景。

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE1LmNuYmxvZ3MuY29tL2Jsb2cvMTEzMDA4My8yMDE3MDUvMTEzMDA4My0yMDE3MDUyNjIxMjkxNDI0Ny0zMzcwNzAwNzkucG5n?x-oss-process=image/format,png)

<center>图4 PASCAL-Context数据集示例</center><br></br>







### 5.2. 2.5维数据集

### 5.3. 3维数据集

## 4.前景展望

​		虽然语义分割任务属于计算机图像视觉方向的基础任务之一，但是其对于很对高级任务的支持至关重要，目前也有着许多未来研究的可能方向。

1. **三维数据集**：充分利用三维数据的一些方法已经开始出现，但是，即使是最新的方案，仍然缺乏对于最重要的构成成分之一即数据的考虑。目前急需一个大规模三维语义分割数据集，但这相对于其低维部分来说是较难创建的。虽然已经有了一些不错的工作，仍然需要更多、更好、更富变化的数据集的出现。值得注意的是，真实世界的三维数据是极其重要的，因为目前几乎所有的工作都是使用的合成数据集。三维数据重要性的一个证明便是，2018年ILSVRC将会创建三维数据。
2. **序列数据集**：三维数据集上大规模数据集缺乏的问题同样影响到了视频序列分割问题。目前仅有少数几个数据集是基于序列的，这些数据集对于利用时间序列信息的方法的发展很有利。从本质上将二维及三维高质量数据联系起来必将引领新的研究方向。
3. **使用图卷积网络（GCN）对点云进行分割**：如之前所述，处理三维数据如点云等目前尚未解决，由于点云内在的无序性及非结构性，传统的架构如CNN等不能直接予以应用，除非使用某种离散化手段使其结构化。一个靠谱的研究方向便致力于将点云处理为图，然后在其上应用卷积[109,110,111]。这种做法的好处便是在不量化数据的基础上保留了每个维度上的空间信息。
4. **上下文知识**：虽然FCN是语义分割领域中的一种坚实的方法，但是FCN网络缺乏对于上下文等特征的建模，而这些信息有可能会提高准确率。将CRF重写为RNN来创造一种端对端的解决方法看起来是一个靠谱的方法，可以提高真实生活场景下的性能。多尺度及特征融合方法也取得了较大的进展。总之，这些方法已经取得了不小的进步，但是仍然有许多问题亟待解决。
5. **实时分割**：在很多应用场景下，准确率是重要的，但是，能够处理达到常见的摄像机帧率（至少25帧每秒）的输入速度也是很关键的。目前多数的方法远远达不到这个帧率，比如，FCN-8处理一张低分辨率的PASCAL VOC数据集中的图像需要100ms，同时，CRFasRNN需要500ms。因此，接下来几年，我们期待会有一系列的工作关注于实时处理的限定，这些工作将必须在准确率与运行时间之间寻求一个平衡。
6. **存储空间**：某些平台受限于其存储空间。分割网络一般需要较大的存储空间，从而可以同时进行推理与训练。为了适应各种设备，网络必须要简单。虽然这可以通过降低复杂性（一般会牺牲准确率）来简单地实现，但是还是可以采取另外的办法。剪枝是一种靠谱的研究方向，可以用来简化网络，使得网络在保留多数信息的同时变得轻量化，也因此同时保留了原网络的准确率。
7. **序列数据的时间一致性**：一些方法解决了视频或序列分割的问题，但是他们有些未利用时间序列信息来提高准确率或效率。然而，没有一种方法解决了一致性的问题。对于一个应用在视频流上的分割系统来说，一致性信息是重要的，不仅可以逐帧地处理数据，还可以对整个片段的处理保持一致，而不需要通过平滑为序列预测出的像素级别的标签而产生人工的信息。
8. **多视角整合**：在最近提出的分割网络上应用多视角信息目前仅仅限于RGB-D摄像机相关的场景，尤其是致力于单一物体分割的情况。

## 参考文献

​		[1] [语义分割技术综述](https://blog.csdn.net/u011435933/article/details/105198437/)

​		[2] [语义分割|发展综述](https://zhuanlan.zhihu.com/p/37618829)

​		[3] [图像语义分割论文综述](https://zhuanlan.zhihu.com/p/265994777)

​		[4] [全卷积网络FCN详解](https://zhuanlan.zhihu.com/p/30195134)

​		[5] [语义分割江湖那些事儿——从Semantic Segmentation 说起](https://bbs.cvmart.net/articles/263)

​		[6] [Image Segmentation Using Deep Learning: A Survey](https://arxiv.org/abs/2001.05566)

​		[7] [Global Convolutional Network(GCN)](https://arxiv.org/abs/1703.02719)

​		[8] 
