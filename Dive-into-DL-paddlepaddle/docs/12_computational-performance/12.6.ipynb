{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 多GPU的简洁实现\n",
    ":label:`sec_multi_gpu_concise`\n",
    "\n",
    "每个新模型的并行计算都从零开始实现是无趣的。此外，优化同步工具以获得高性能也是有好处的。下面我们将展示如何使用深度学习框架的高级API来实现这一点。数学和算法与 :numref:`sec_multi_gpu`中的相同。不出所料，你至少需要两个GPU来运行本节的代码。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 2,
    "scrolled": true,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "# 在notebook下面单GPU可以执行，多GPU会提示使用python -m paddle.distributed.launch xx.py格式方式执行。\n",
    "import paddle\n",
    "from paddle import nn\n",
    "import d2l.paddle as d2l\n",
    "# 导入必要分布式训练的依赖包\n",
    "from paddle.distributed import fleet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 3
   },
   "source": [
    "## [**简单网络**]\n",
    "\n",
    "让我们使用一个比 :numref:`sec_multi_gpu`的LeNet更有意义的网络，它依然能够容易地和快速地训练。我们选择的是 :cite:`He.Zhang.Ren.ea.2016`中的ResNet-18。因为输入的图像很小，所以稍微修改了一下。与 :numref:`sec_resnet`的区别在于，我们在开始时使用了更小的卷积核、步长和填充，而且删除了最大汇聚层。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 5,
    "scrolled": true,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "def resnet18(num_classes, in_channels=1):\n",
    "    \"\"\"稍加修改的ResNet-18模型\"\"\"\n",
    "    def resnet_block(in_channels, out_channels, num_residuals,\n",
    "                     first_block=False):\n",
    "        blk = []\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                blk.append(d2l.Residual(in_channels, out_channels,\n",
    "                                        use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                blk.append(d2l.Residual(out_channels, out_channels))\n",
    "        return nn.Sequential(*blk)\n",
    "\n",
    "    # 该模型使用了更小的卷积核、步长和填充，而且删除了最大汇聚层\n",
    "    net = nn.Sequential(\n",
    "        nn.Conv2D(in_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2D(64),\n",
    "        nn.ReLU())\n",
    "    net.add_sublayer(\"resnet_block1\", resnet_block(\n",
    "        64, 64, 2, first_block=True))\n",
    "    net.add_sublayer(\"resnet_block2\", resnet_block(64, 128, 2))\n",
    "    net.add_sublayer(\"resnet_block3\", resnet_block(128, 256, 2))\n",
    "    net.add_sublayer(\"resnet_block4\", resnet_block(256, 512, 2))\n",
    "    net.add_sublayer(\"global_avg_pool\", nn.AdaptiveAvgPool2D((1,1)))\n",
    "    net.add_sublayer(\"fc\", nn.Sequential(nn.Flatten(),\n",
    "                                       nn.Linear(512, num_classes)))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "## 网络初始化\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "我们将在训练回路中初始化网络。请参见 :numref:`sec_numerical_stability`复习初始化方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 10,
    "scrolled": true,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "# 为了展示方便，飞桨的初始化网络等代码放入训练代码中实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 17
   },
   "source": [
    "## [**训练**]\n",
    "\n",
    "如前所述，用于训练的代码需要执行几个基本功能才能实现高效并行：\n",
    "\n",
    "* 需要在所有设备上初始化网络参数。\n",
    "* 在数据集上迭代时，要将小批量数据分配到所有设备上。\n",
    "* 跨设备并行计算损失及其梯度。\n",
    "* 聚合梯度，并相应地更新参数。\n",
    "\n",
    "最后，并行地计算精确度和发布网络的最终性能。除了需要拆分和聚合数据外，训练代码与前几章的实现非常相似。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 19,
    "scrolled": true,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def train_resnet(epochs=1, batch_size=32, lr=0.001):\n",
    "    momentum_rate = 0.9 # 冲量\n",
    "    l2_decay = 1e-4 # 权重衰减\n",
    "\n",
    "    # 初始化Fleet环境\n",
    "    fleet.init(is_collective=True)\n",
    "    resnet = resnet18(10) # 10分类\n",
    "    optimizer = paddle.optimizer.Momentum(\n",
    "        learning_rate=lr,\n",
    "        momentum=momentum_rate,\n",
    "        weight_decay=paddle.regularizer.L2Decay(l2_decay),\n",
    "        parameters=resnet.parameters())\n",
    "    # 设置分布式训练使用的优化器\n",
    "    optimizer = fleet.distributed_optimizer(optimizer)\n",
    "\n",
    "    # 通过Fleet API获取分布式model，用于支持分布式训练\n",
    "    resnet = fleet.distributed_model(resnet)\n",
    "\n",
    "    train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "    # 用于单GPU环境Notebook下绘图\n",
    "    animator = d2l.Animator('epoch', 'test acc', xlim=[1, epochs])\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        resnet.train()\n",
    "\n",
    "        for batch_id, data in enumerate(train_iter):\n",
    "            img, label = data\n",
    "            label.stop_gradient = True\n",
    "\n",
    "            out = resnet(img)\n",
    "\n",
    "            loss = paddle.nn.functional.cross_entropy(input=out, label=label)\n",
    "            avg_loss = paddle.mean(x=loss)\n",
    "            acc_top1 = paddle.metric.accuracy(input=out, label=label, k=1)\n",
    "            acc_top5 = paddle.metric.accuracy(input=out, label=label, k=5)\n",
    "\n",
    "            avg_loss.backward()\n",
    "            optimizer.step()\n",
    "            resnet.clear_gradients()\n",
    "\n",
    "            if batch_id % 50 == 0: # 每50个batch显示训练信息\n",
    "                print(\"[Epoch %d, batch %d] loss: %.5f, acc1: %.5f, acc5: %.5f\" % (epoch, batch_id, avg_loss, acc_top1, acc_top5))\n",
    "        animator.add(epoch + 1, (d2l.evaluate_accuracy_gpu(resnet, test_iter),))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "让我们看看这在实践中是如何运作的。我们先[**在单个GPU上训练网络**]进行预热。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 22,
    "scrolled": true,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "# 此为单GPU环境命令。若为多GPU环境Notebook里，会报错： \n",
    "# CUDA_VISIBLE_DEVICES shoule be set only 1 card if you use `python` to launch fleet program.\n",
    "# 在命令行下执行此命令即可“!python -m paddle.distributed.launch multigpu.py”\n",
    "train_resnet(epochs=10, batch_size=256, lr=0.05) # 若为多GPU，学习率需要乘以相应倍数以达到较好效果，比如2GPU lr=0.1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 23
   },
   "source": [
    "接下来我们[**使用2个GPU进行训练**]。与 :numref:`sec_multi_gpu`中评估的LeNet相比，ResNet-18的模型要复杂得多。这就是显示并行化优势的地方，计算所需时间明显大于同步参数需要的时间。因为并行化开销的相关性较小，因此这种操作提高了模型的可伸缩性。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 25,
    "scrolled": true,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "%%writefile multigpu.py\n",
    "# 飞桨多GPU程序，不管单GPU环境还是多GPU环境，都可以在不修改代码，不修改执行命令的情况下正常执行。命令使用python -m paddle.distributed.launch xx.py格式方式执行。\n",
    "import paddle\n",
    "from paddle import nn\n",
    "import d2l.paddle as d2l\n",
    "\n",
    "# 导入必要分布式训练的依赖包\n",
    "from paddle.distributed import fleet\n",
    "\n",
    "#@save\n",
    "def resnet18(num_classes, in_channels=1):\n",
    "    \"\"\"稍加修改的ResNet-18模型\"\"\"\n",
    "    def resnet_block(in_channels, out_channels, num_residuals,\n",
    "                     first_block=False):\n",
    "        blk = []\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                blk.append(d2l.Residual(in_channels, out_channels,\n",
    "                                        use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                blk.append(d2l.Residual(out_channels, out_channels))\n",
    "        return nn.Sequential(*blk)\n",
    "\n",
    "    # 该模型使用了更小的卷积核、步长和填充，而且删除了最大汇聚层\n",
    "    net = nn.Sequential(\n",
    "        nn.Conv2D(in_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2D(64),\n",
    "        nn.ReLU())\n",
    "    net.add_sublayer(\"resnet_block1\", resnet_block(\n",
    "        64, 64, 2, first_block=True))\n",
    "    net.add_sublayer(\"resnet_block2\", resnet_block(64, 128, 2))\n",
    "    net.add_sublayer(\"resnet_block3\", resnet_block(128, 256, 2))\n",
    "    net.add_sublayer(\"resnet_block4\", resnet_block(256, 512, 2))\n",
    "    net.add_sublayer(\"global_avg_pool\", nn.AdaptiveAvgPool2D((1,1)))\n",
    "    net.add_sublayer(\"fc\", nn.Sequential(nn.Flatten(),\n",
    "                                       nn.Linear(512, num_classes)))\n",
    "    return net\n",
    "\n",
    "# 训练\n",
    "def train_resnet(epochs=1, batch_size=32, lr=0.001):\n",
    "    momentum_rate = 0.9 # 冲量\n",
    "    l2_decay = 1e-4 # 权重衰减\n",
    "\n",
    "    # 初始化Fleet环境\n",
    "    fleet.init(is_collective=True)\n",
    "    resnet = resnet18(10) # 10分类\n",
    "    optimizer = paddle.optimizer.Momentum(\n",
    "        learning_rate=lr,\n",
    "        momentum=momentum_rate,\n",
    "        weight_decay=paddle.regularizer.L2Decay(l2_decay),\n",
    "        parameters=resnet.parameters())\n",
    "    # 设置分布式训练使用的优化器\n",
    "    optimizer = fleet.distributed_optimizer(optimizer)\n",
    "\n",
    "    # 通过Fleet API获取分布式model，用于支持分布式训练\n",
    "    resnet = fleet.distributed_model(resnet)\n",
    "\n",
    "    train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "    # 用于单GPU环境Notebook下绘图\n",
    "    animator = d2l.Animator('epoch', 'test acc', xlim=[1, epochs])\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        resnet.train()\n",
    "\n",
    "        for batch_id, data in enumerate(train_iter):\n",
    "            img, label = data\n",
    "            label.stop_gradient = True\n",
    "\n",
    "            out = resnet(img)\n",
    "\n",
    "            loss = paddle.nn.functional.cross_entropy(input=out, label=label)\n",
    "            avg_loss = paddle.mean(x=loss)\n",
    "            acc_top1 = paddle.metric.accuracy(input=out, label=label, k=1)\n",
    "            acc_top5 = paddle.metric.accuracy(input=out, label=label, k=5)\n",
    "\n",
    "            avg_loss.backward()\n",
    "            optimizer.step()\n",
    "            resnet.clear_gradients()\n",
    "\n",
    "            if batch_id % 50 == 0: # 每50个batch显示训练信息\n",
    "                print(\"[Epoch %d, batch %d] loss: %.5f, acc1: %.5f, acc5: %.5f\" % (epoch, batch_id, avg_loss, acc_top1, acc_top5))\n",
    "        animator.add(epoch + 1, (d2l.evaluate_accuracy_gpu(resnet, test_iter),))\n",
    "\n",
    "if __name__ == \"__main__\" :\n",
    "    train_resnet(epochs=10, batch_size=256, lr=0.05) # 若为多GPU，学习率需要乘以相应倍数以达到较好效果，比如2GPU lr=0.1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python -m paddle.distributed.launch multigpu.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 26
   },
   "source": [
    "## 小结\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 28,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "* 神经网络可以在（可找到数据的）单GPU上进行自动评估。\n",
    "* 每台设备上的网络需要先初始化，然后再尝试访问该设备上的参数，否则会遇到错误。\n",
    "* 优化算法在多个GPU上自动聚合。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 29
   },
   "source": [
    "## 练习\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 31,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "1. 本节使用ResNet-18，请尝试不同的迭代周期数、批量大小和学习率，以及使用更多的GPU进行计算。如果使用$16$个GPU（例如，在AWS p2.16xlarge实例上）尝试此操作，会发生什么？\n",
    "1. 有时候不同的设备提供了不同的计算能力，我们可以同时使用GPU和CPU，那应该如何分配工作？为什么？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 33,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/2803)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
