{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 编译器和解释器\n",
    ":label:`sec_hybridize`\n",
    "\n",
    "目前为止，本书主要关注的是*命令式编程*（imperative programming）。\n",
    "命令式编程使用诸如`print`、“`+`”和`if`之类的语句来更改程序的状态。\n",
    "考虑下面这段简单的命令式程序：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:24:27.565350Z",
     "iopub.status.busy": "2022-03-02T12:24:27.564744Z",
     "iopub.status.idle": "2022-03-02T12:24:27.570741Z",
     "shell.execute_reply": "2022-03-02T12:24:27.569994Z",
     "shell.execute_reply.started": "2022-03-02T12:24:27.565317Z"
    },
    "origin_pos": 1,
    "scrolled": true,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "def fancy_func(a, b, c, d):\n",
    "    e = add(a, b)\n",
    "    f = add(c, d)\n",
    "    g = add(e, f)\n",
    "    return g\n",
    "\n",
    "print(fancy_func(1, 2, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 2
   },
   "source": [
    "Python是一种*解释型语言*（interpreted language）。因此，当对上面的`fancy_func`函数求值时，它按顺序执行函数体的操作。也就是说，它将通过对`e = add(a, b)`求值，并将结果存储为变量`e`，从而更改程序的状态。接下来的两个语句`f = add(c, d)`和`g = add(e, f)`也将执行类似地操作，即执行加法计算并将结果存储为变量。 :numref:`fig_compute_graph`说明了数据流。\n",
    "\n",
    "![命令式编程中的数据流](../img/computegraph.svg)\n",
    ":label:`fig_compute_graph`\n",
    "\n",
    "尽管命令式编程很方便，但可能效率不高。一方面原因，Python会单独执行这三个函数的调用，而没有考虑`add`函数在`fancy_func`中被重复调用。如果在一个GPU（甚至多个GPU）上执行这些命令，那么Python解释器产生的开销可能会非常大。此外，它需要保存`e`和`f`的变量值，直到`fancy_func`中的所有语句都执行完毕。这是因为程序不知道在执行语句`e = add(a, b)`和`f = add(c, d)`之后，其他部分是否会使用变量`e`和`f`。\n",
    "\n",
    "## 符号式编程\n",
    "\n",
    "考虑另一种选择*符号式编程*（symbolic programming），即代码通常只在完全定义了过程之后才执行计算。这个策略被多个深度学习框架使用，包括Theano和TensorFlow（后者已经获得了命令式编程的扩展）。一般包括以下步骤：\n",
    "\n",
    "1. 定义计算流程。\n",
    "1. 将流程编译成可执行的程序。\n",
    "1. 给定输入，调用编译好的程序执行。\n",
    "\n",
    "这将允许进行大量的优化。首先，在大多数情况下，我们可以跳过Python解释器。从而消除因为多个更快的GPU与单个CPU上的单个Python线程搭配使用时产生的性能瓶颈。其次，编译器可以将上述代码优化和重写为`print((1 + 2) + (3 + 4))`甚至`print(10)`。因为编译器在将其转换为机器指令之前可以看到完整的代码，所以这种优化是可以实现的。例如，只要某个变量不再需要，编译器就可以释放内存（或者从不分配内存），或者将代码转换为一个完全等价的片段。下面，我们将通过模拟命令式编程来进一步了解符号式编程的概念。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:24:27.572768Z",
     "iopub.status.busy": "2022-03-02T12:24:27.572313Z",
     "iopub.status.idle": "2022-03-02T12:24:27.577942Z",
     "shell.execute_reply": "2022-03-02T12:24:27.577206Z",
     "shell.execute_reply.started": "2022-03-02T12:24:27.572740Z"
    },
    "origin_pos": 3,
    "scrolled": true,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def add(a, b):\n",
      "    return a + b\n",
      "\n",
      "def fancy_func(a, b, c, d):\n",
      "    e = add(a, b)\n",
      "    f = add(c, d)\n",
      "    g = add(e, f)\n",
      "    return g\n",
      "print(fancy_func(1, 2, 3, 4))\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "def add_():\n",
    "    return '''\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "'''\n",
    "\n",
    "def fancy_func_():\n",
    "    return '''\n",
    "def fancy_func(a, b, c, d):\n",
    "    e = add(a, b)\n",
    "    f = add(c, d)\n",
    "    g = add(e, f)\n",
    "    return g\n",
    "'''\n",
    "\n",
    "def evoke_():\n",
    "    return add_() + fancy_func_() + 'print(fancy_func(1, 2, 3, 4))'\n",
    "\n",
    "prog = evoke_()\n",
    "print(prog)\n",
    "y = compile(prog, '', 'exec')\n",
    "exec(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "命令式（解释型）编程和符号式编程的区别如下：\n",
    "\n",
    "* 命令式编程更容易使用。在Python中，命令式编程的大部分代码都是简单易懂的。命令式编程也更容易调试，这是因为无论是获取和打印所有的中间变量值，或者使用Python的内置调试工具都更加简单。\n",
    "* 符号式编程运行效率更高，更易于移植。符号式编程更容易在编译期间优化代码，同时还能够将程序移植到与Python无关的格式中，从而允许程序在非Python环境中运行，避免了任何潜在的与Python解释器相关的性能问题。\n",
    "\n",
    "## 混合式编程\n",
    "\n",
    "历史上，大部分深度学习框架都在命令式编程与符号式编程之间进行选择。例如，Theano、TensorFlow（灵感来自前者）、Keras、CNTK和飞桨采用了符号式编程。相反地，Chainer和PyTorch采取了命令式编程。在后来的版本更新中，TensorFlow2.0、Keras和飞桨增加了命令式编程。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "如上所述，飞桨是基于命令式编程并且使用动态计算图。为了能够利用符号式编程的可移植性和效率，开发人员思考能否将这两种编程模型的优点结合起来，于是就产生了飞桨2.0版本。飞桨2.0及以上版本允许用户使用纯命令式编程进行开发和调试，同时能够一行代码转换为符号式程序，以便在需要产品级计算性能和部署时使用。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "## `Sequential`的混合式编程\n",
    "\n",
    "要了解混合式编程的工作原理，最简单的方法是考虑具有多层的深层网络。按照惯例，Python解释器需要执行所有层的代码来生成一条指令，然后将该指令转发到CPU或GPU。对于单个的（快速的）计算设备，这不会导致任何重大问题。另一方面，如果我们使用先进的8-GPU服务器，比如AWS P3dn.24xlarge实例，Python将很难让所有的GPU都保持忙碌。如何解决这个瓶颈，我们可以到后面的多GPU训练和多GPU的简洁实现两节寻找答案。现在，首先，我们定义一个简单的多层感知机。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:24:27.579224Z",
     "iopub.status.busy": "2022-03-02T12:24:27.578867Z",
     "iopub.status.idle": "2022-03-02T12:24:27.639047Z",
     "shell.execute_reply": "2022-03-02T12:24:27.638373Z",
     "shell.execute_reply.started": "2022-03-02T12:24:27.579199Z"
    },
    "origin_pos": 10,
    "scrolled": true,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[1, 2], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
       "       [[-0.12194420,  0.29053691]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import paddle\n",
    "from paddle import nn\n",
    "from paddle.jit import to_static\n",
    "from paddle.static import InputSpec\n",
    "from d2l import paddle as d2l\n",
    "\n",
    "\n",
    "# 生产网络的工厂模式\n",
    "# 因为飞桨动态图太快了，需要增加更多的线形图来对比，比如42层。\n",
    "def get_net():\n",
    "    blocks = [nn.Linear(512, 512) for i in range(42)] + [\n",
    "        nn.Linear(512, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 2)\n",
    "    ]\n",
    "    net = nn.Sequential(*blocks)\n",
    "    return net\n",
    "\n",
    "x = paddle.randn((1, 512))\n",
    "net = get_net()\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 13,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "通过使用`paddle.jit.to_static`函数来转换模型，我们就有能力编译和优化多层感知机中的计算，而模型的计算结果保持不变。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:24:27.640847Z",
     "iopub.status.busy": "2022-03-02T12:24:27.640390Z",
     "iopub.status.idle": "2022-03-02T12:24:27.848175Z",
     "shell.execute_reply": "2022-03-02T12:24:27.847591Z",
     "shell.execute_reply.started": "2022-03-02T12:24:27.640819Z"
    },
    "origin_pos": 16,
    "scrolled": true,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[1, 2], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
       "       [[-0.12194420,  0.29053691]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = to_static(net)\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 19,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "我们编写与之前相同的代码，再使用`paddle.jit.to_static`简单地转换模型，当完成这些任务后，网络就将得到优化（我们将在下面对性能进行基准测试）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 21
   },
   "source": [
    "### 通过混合式编程加速\n",
    "\n",
    "为了证明通过编译获得了性能改进，我们比较了混合编程前后执行`net(x)`所需的时间。让我们先定义一个度量时间的类，它在本章中在衡量（和改进）模型性能时将非常有用。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:24:27.849567Z",
     "iopub.status.busy": "2022-03-02T12:24:27.849131Z",
     "iopub.status.idle": "2022-03-02T12:24:27.853504Z",
     "shell.execute_reply": "2022-03-02T12:24:27.852998Z",
     "shell.execute_reply.started": "2022-03-02T12:24:27.849539Z"
    },
    "origin_pos": 22,
    "scrolled": true,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "class Benchmark:\n",
    "    \"\"\"用于测量运行时间\"\"\"\n",
    "    def __init__(self, description='Done'):\n",
    "        self.description = description\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.timer = d2l.Timer()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        print(f'{self.description}: {self.timer.stop():.4f} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 24,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "现在我们可以调用网络两次，一次使用动态图命令式编程，一次使用静态图符号式编程。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:24:27.854648Z",
     "iopub.status.busy": "2022-03-02T12:24:27.854291Z",
     "iopub.status.idle": "2022-03-02T12:24:33.215292Z",
     "shell.execute_reply": "2022-03-02T12:24:33.214681Z",
     "shell.execute_reply.started": "2022-03-02T12:24:27.854624Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paddle动态图命令式编程: 3.0506 sec\n",
      "Paddle静态图符号式编程: 2.2169 sec\n"
     ]
    }
   ],
   "source": [
    "net = get_net()\n",
    "with Benchmark('Paddle动态图命令式编程'):\n",
    "    for i in range(1000): net(x)\n",
    "\n",
    "x_spec = InputSpec(shape=[-1, 512], name='x') \n",
    "net = to_static(get_net(),input_spec=[x_spec])\n",
    "with Benchmark('Paddle静态图符号式编程'):\n",
    "    for i in range(1000): net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 30,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "如以上结果所示，在`nn.Sequential`的实例被函数`paddle.jit.to_static`脚本化后，通过使用符号式编程提高了计算性能。事实上飞桨非常巧妙的实现了动静自然统一，完备实现了一键式动静转换，也就是只需要一条命令，就可以实现动静转换，具体见附录部分。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 32
   },
   "source": [
    "### 序列化\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 34,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "编译模型的好处之一是我们可以将模型及其参数序列化（保存）到磁盘。这允许这些训练好的模型部署到其他设备上，并且还能方便地使用其他前端编程语言。同时，通常编译模型的代码执行速度也比命令式编程更快。让我们看看`paddle.jit.save`的实际功能。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:24:33.217133Z",
     "iopub.status.busy": "2022-03-02T12:24:33.216853Z",
     "iopub.status.idle": "2022-03-02T12:24:34.952980Z",
     "shell.execute_reply": "2022-03-02T12:24:34.952101Z",
     "shell.execute_reply.started": "2022-03-02T12:24:33.217106Z"
    },
    "origin_pos": 37,
    "scrolled": true,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 aistudio aistudio  43M 3月   2 20:24 my_net.pdiparams\n",
      "-rw-r--r-- 1 aistudio aistudio 4.4K 3月   2 20:24 my_net.pdiparams.info\n",
      "-rw-r--r-- 1 aistudio aistudio 660K 3月   2 20:24 my_net.pdmodel\n"
     ]
    }
   ],
   "source": [
    "paddle.jit.save(net, './my_net')\n",
    "!ls -lh my_net*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 50
   },
   "source": [
    "## 小结\n",
    "\n",
    "* 命令式编程使得新模型的设计变得容易，因为可以依据控制流编写代码，并拥有相对成熟的Python软件生态。\n",
    "* 符号式编程要求我们先定义并且编译程序，然后再执行程序，其好处是提高了计算性能。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 52
   },
   "source": [
    "## 练习\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 54,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "1. 回顾前几章中你感兴趣的模型，你能提高它们的计算性能吗？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 附录：一键动静转换\n",
    "动态图和静态图可以写成一份代码，唯一不同的地方就是使用`paddle.enable_static()`切换到静态图，使用`paddle.disable_static()`切换到动态图。飞桨默认是动态图，所以`paddle.disable_static()`这句话是可以省略的。需要注意，在实验中切换到静态图后，若再执行动态图代码（整个《动手学深度学习》的几乎其它所有项目和代码都是动态图代码），不要忘记用`paddle.disable_static()`切换回动态图。\n",
    "\n",
    "为了更好的表现动静统一，动静两者代码保持一模一样，我们单独写了一个ToArray类，以完成数据转换为ndarray float32类型的任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:24:34.954795Z",
     "iopub.status.busy": "2022-03-02T12:24:34.954464Z",
     "iopub.status.idle": "2022-03-02T12:24:34.959797Z",
     "shell.execute_reply": "2022-03-02T12:24:34.959257Z",
     "shell.execute_reply.started": "2022-03-02T12:24:34.954767Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from paddle.vision.transforms import BaseTransform\n",
    "class ToArray(BaseTransform):\n",
    "    \"\"\"Convert a ``PIL.Image`` to ``numpy.ndarray`` \n",
    "    \"\"\"\n",
    "    def __init__(self, keys=None):\n",
    "        super(ToArray, self).__init__(keys)\n",
    "        \n",
    "    def _apply_image(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL.Image|np.ndarray): Image to be converted to numpy.ndarray.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Converted image.\n",
    "        \"\"\"\n",
    "        #转换为ndarray类型，并调整uint8类型到float32类型\n",
    "        out = np.array(img, dtype='float32')\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 静态图\n",
    "在AIStudio的Tesla V100显卡环境下，我们看到训练速度为`3ms/step`，整个项目执行耗时9.7秒。\n",
    "如果是第一次执行，会因为数据集下载而多消耗时间，只要再重新运行一次即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:24:34.960990Z",
     "iopub.status.busy": "2022-03-02T12:24:34.960664Z",
     "iopub.status.idle": "2022-03-02T12:24:44.990867Z",
     "shell.execute_reply": "2022-03-02T12:24:44.990230Z",
     "shell.execute_reply.started": "2022-03-02T12:24:34.960965Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/1\n",
      "step  400/1875 - loss: 13.3404 - acc_top1: 0.8383 - acc_top2: 0.9245 - 3ms/step\n",
      "step  800/1875 - loss: 2.1486 - acc_top1: 0.8819 - acc_top2: 0.9486 - 3ms/step\n",
      "step 1200/1875 - loss: 5.9143e-04 - acc_top1: 0.9018 - acc_top2: 0.9597 - 3ms/step\n",
      "step 1600/1875 - loss: 0.3167 - acc_top1: 0.9116 - acc_top2: 0.9650 - 3ms/step\n",
      "step 1875/1875 - loss: 0.0472 - acc_top1: 0.9165 - acc_top2: 0.9676 - 3ms/step\n",
      "Eval begin...\n",
      "step  40/157 - loss: 1.0460 - acc_top1: 0.9418 - acc_top2: 0.9840 - 4ms/step\n",
      "step  80/157 - loss: 1.7192e-04 - acc_top1: 0.9400 - acc_top2: 0.9828 - 4ms/step\n",
      "step 120/157 - loss: 0.3291 - acc_top1: 0.9477 - acc_top2: 0.9852 - 4ms/step\n",
      "step 157/157 - loss: 0.0000e+00 - acc_top1: 0.9492 - acc_top2: 0.9859 - 4ms/step\n",
      "Eval samples: 10000\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "from paddle.vision.transforms import BaseTransform, Compose, Transpose\n",
    "from paddle.static import InputSpec\n",
    "\n",
    "# 一句话切换动态图和静态图，默认是动态图模式，也可以用命令paddle.disable_static()显式用打开动态图模式。\n",
    "paddle.enable_static()\n",
    "# paddle.disable_static() \n",
    "\n",
    "transforms = Compose([Transpose(), ToArray()])\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transforms)\n",
    "test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transforms)\n",
    "\n",
    "\n",
    "# 静态图需要指定输入参数的张量信息\n",
    "x_spec = InputSpec(shape=[-1, 1, 28, 28], dtype='float32', name='x') \n",
    "y_spec = InputSpec(shape=[-1, 1], dtype='int64', name='y')\n",
    "# 直接调用飞桨即成的lenet模型，Model包含了训练功能\n",
    "lenet = paddle.vision.models.LeNet()\n",
    "model = paddle.Model(lenet,inputs=x_spec, labels=y_spec)\n",
    "\n",
    "# 设置训练模型所需的optimizer, loss, metric\n",
    "model.prepare(\n",
    "    paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters()),\n",
    "    paddle.nn.CrossEntropyLoss(),\n",
    "    paddle.metric.Accuracy(topk=(1, 2))\n",
    "    )\n",
    "\n",
    "def train():\n",
    "    # 启动训练\n",
    "    model.fit(train_dataset, epochs=1, batch_size=32, log_freq=400)\n",
    "\n",
    "    # 启动评估\n",
    "    model.evaluate(test_dataset, log_freq=40, batch_size=64)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    train()\n",
    "\n",
    "paddle.disable_static() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 动态图\n",
    "在AIStudio的Tesla V100显卡环境下，我们看到训练速度为`6ms/step`，整个项目执行耗时17.1秒。可见静态图对速度的加成还是很可观的，对比动态图加速效果显著！\n",
    "\n",
    "尽管可以一键转换动态图和静态图，非常方便，但是我们仔细看一下代码，会发现跟平时写的动态图代码有很大的不同，比平常的动态图代码写起来要麻烦一些。一键转换为静态图，提高了运行速度，但是相应的也提高了写代码的难度。代码难易排序为： 纯静态图代码>动静统一代码>纯动态图代码，代码运行速度从快到慢为：纯静态图代码>=动静统一代码>纯动态图代码。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:24:44.992284Z",
     "iopub.status.busy": "2022-03-02T12:24:44.991852Z",
     "iopub.status.idle": "2022-03-02T12:25:01.612169Z",
     "shell.execute_reply": "2022-03-02T12:25:01.611585Z",
     "shell.execute_reply.started": "2022-03-02T12:24:44.992257Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/1\n",
      "step  400/1875 - loss: 4.0589 - acc_top1: 0.8323 - acc_top2: 0.9166 - 6ms/step\n",
      "step  800/1875 - loss: 0.6345 - acc_top1: 0.8720 - acc_top2: 0.9438 - 6ms/step\n",
      "step 1200/1875 - loss: 0.5827 - acc_top1: 0.8905 - acc_top2: 0.9551 - 6ms/step\n",
      "step 1600/1875 - loss: 0.1877 - acc_top1: 0.9002 - acc_top2: 0.9600 - 6ms/step\n",
      "step 1875/1875 - loss: 0.1349 - acc_top1: 0.9043 - acc_top2: 0.9626 - 6ms/step\n",
      "Eval begin...\n",
      "step  40/157 - loss: 0.2160 - acc_top1: 0.9367 - acc_top2: 0.9805 - 7ms/step\n",
      "step  80/157 - loss: 0.2853 - acc_top1: 0.9373 - acc_top2: 0.9805 - 6ms/step\n",
      "step 120/157 - loss: 0.1427 - acc_top1: 0.9466 - acc_top2: 0.9833 - 6ms/step\n",
      "step 157/157 - loss: 5.1353e-04 - acc_top1: 0.9488 - acc_top2: 0.9847 - 6ms/step\n",
      "Eval samples: 10000\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "from paddle.vision.transforms import BaseTransform, Compose, Transpose\n",
    "from paddle.static import InputSpec\n",
    "\n",
    "# 一句话切换动态图和静态图，默认是动态图模式，也可以用命令paddle.disable_static()显式用打开动态图模式。\n",
    "# paddle.enable_static()\n",
    "paddle.disable_static() \n",
    "\n",
    "transforms = Compose([Transpose(), ToArray()])\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transforms)\n",
    "test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transforms)\n",
    "\n",
    "\n",
    "# 静态图需要指定输入参数的张量信息\n",
    "x_spec = InputSpec(shape=[-1, 1, 28, 28], dtype='float32', name='x') \n",
    "y_spec = InputSpec(shape=[-1, 1], dtype='int64', name='y')\n",
    "# 直接调用飞桨即成的lenet模型，Model包含了训练功能\n",
    "lenet = paddle.vision.models.LeNet()\n",
    "model = paddle.Model(lenet,inputs=x_spec, labels=y_spec)\n",
    "\n",
    "# 设置训练模型所需的optimizer, loss, metric\n",
    "model.prepare(\n",
    "    paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters()),\n",
    "    paddle.nn.CrossEntropyLoss(),\n",
    "    paddle.metric.Accuracy(topk=(1, 2))\n",
    "    )\n",
    "\n",
    "def train():\n",
    "    # 启动训练\n",
    "    model.fit(train_dataset, epochs=1, batch_size=32, log_freq=400)\n",
    "\n",
    "    # 启动评估\n",
    "    model.evaluate(test_dataset, log_freq=40, batch_size=64)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 56,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/2788)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
